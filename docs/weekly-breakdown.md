---
sidebar_label: Weekly Breakdown
sidebar_position: 99
---

# 13-Week Mastery Roadmap (2025 Edition)  
**From Zero to Deploying a Vision-Language-Action Humanoid Agent**

| Week | Focus & Deliverables                                                                                   | Outcome by Sunday Night                                                                 |
|------|--------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------|
| **1**  | Physical AI Landscape + ROS 2 Jazzy from Scratch                                                       | Full ROS 2 workspace, publishing/subscribing topics, launch files, debugging with Foxglove |
| **2**  | Deep Dive: Topics, Services, Actions, Parameters, QoS, Lifecycle Nodes                                 | Bullet-proof communication architecture used in industry                                |
| **3**  | URDF/Xacro Mastery + ros2_control + MoveIt2 + robot_state_publisher                                    | 6-DoF arm + mobile base perfectly controlled in RViz                                    |
| **4**  | Real & Simulated Sensors (LiDAR, RGB-D, IMU, GPS) + Noise Modelling + MCAP Recording                   | Professional-grade sensor pipeline ready for SLAM & perception                          |
| **5**  | Gazebo Classic 11 + Realistic Physics + ros2_control + Gazebo-ROS Bridge                               | Fully functional robot running in simulation with 95 %+ real-time factor                |
| **6**  | Advanced Gazebo: Plugins, SDF, Soft Bodies, Domain Randomisation + Intro to Gazebo Sim (Harmonic)     | Production-grade simulation used by Boston Dynamics & NASA                               |
| **7**  | Unity Robotics + ROS-TCP-Connector + High-Fidelity Rendering                                           | Photorealistic robot in Unity responding to ROS 2 commands                               |
| **8**  | Synthetic Data Generation in Unity & Isaac Sim + Replicator + Domain Randomisation                     | 50 k–100 k perfectly labelled images generated in < 8 hours                              |
| **9**  | NVIDIA Isaac ROS – GPU-Accelerated Perception (YOLOv8, AprilTag, V-SLAM, NITROS, GEMINI)               | 100+ Hz perception pipeline on Jetson Orin / RTX 4090                                    |
| **10** | Isaac Sim (Omniverse 2025) – Ray-traced Sensors, PhysX 5, Replicator, MCAP, Sim-to-Real               | Million-image synthetic datasets + perfect Sim2Real transfer                             |
| **11** | Vision-Language-Action Models – OpenVLA-7B, Octo, RT-2-X, RoboFlamingo                                 | Robot executes language commands from a single webcam image                               |
| **12** | Fine-tuning OpenVLA on your own data + LoRA + Speech (Whisper + Piper) + Long-horizon planning         | Your personal VLA agent that follows complex multi-step instructions                    |
| **13** | Capstone Finalisation + Demo Video + GitHub Portfolio + Certificate + Future Trends (2026–2030)      | Industry-ready portfolio project that gets you interviews at Figure, Tesla, 1X, etc.     |

### Bonus Milestones (Built-in)
- **Week 6** → First full robot running autonomously in simulation  
- **Week 10** → 500 k+ synthetic images + trained detector with >95 % mAP  
- **Week 12** → Robot that can “pick the red apple and put it in the blue bowl” on first try  
- **Week 13** → 3–5 minute YouTube demo that goes viral in the robotics community  

### Total Time Investment
- 13 weeks × 12–18 hours/week = 150–230 hours  
- 100 % project-based — every weekend you ship something impressive  

**This is the exact 13-week plan I would follow if I had to become job-ready for a top humanoid startup in 2025.**

Stick to it → and by Week 13 you will have a portfolio that 99 % of robotics engineers on Earth cannot match.

Let’s go build the future — one week at a time.